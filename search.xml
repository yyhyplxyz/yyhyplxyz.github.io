<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[科研方向选择的一点小思考]]></title>
    <url>%2F2018%2F03%2F21%2F%E7%A7%91%E7%A0%94%E6%96%B9%E5%90%91%E9%80%89%E6%8B%A9%E7%9A%84%E4%B8%80%E7%82%B9%E5%B0%8F%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[​ ​ ​ 我觉得出现了上图现象有个原因，人做事一般都要有点奖励和预期奖励来促进多巴胺生产，让自己快乐，也让自己有成就感，成就感也能增加人存在的意义感。机器学习的应用跟做程序开发很像，不需要很多功夫就能打出来很好玩或者很有用的应用。应用打出来的时候也是成就感高涨的时候，会激励自己去做下一个，所以我感觉即使在行业工资差不多的情况下喜欢编程，乐此不疲打代码的很明显比喜欢做会计，乐此不疲来做帐的多。 ​ 做科研和做工程不太一样，做科研很少听说研究成果能应用啥的，蛟龙号，神州，还有做核弹研发的大部分是工程师或者科学家客串工程师。只有机器学习这个领域是即做科学研究又做工程师，所以即使这类方向的毕业生工资没那么高，做这类研究的人相对也会比较多的。现在区块链的研究虽然也会有应用前景，但从我浅薄的知识来看他的应用局限在记录的可信度方面，想比机器学习不是很有趣，而且我感觉区块链该有的东西差不多都有了，比特币都能造出来了。人民日报说拿区块链记账也应该不存在理论上的问题，缺的只是工程师了。各国央行都有说要推行数字货币的，不难推测已经不存在技术难题，剩下的是社会经济制度的变革方面的考虑。 ​ 所以，我觉得区块链相比机器学习更缺的是工程师而不是科学家。而区块链在科研界的热度应该可以类比pc时代软件开发技术的科研热度，移动端时代网络通信方面的研究热度。（我也不清楚那时候这些面热不热门 QUQ） ​ 大胆的预测下，数字货币真的发行的话，很多金融机构应该会凉凉。在那个时代，一切企业的消费记录和信用记录都是公开透明的，金融的信息不对称性会大大降低，投行起码不能从发行承销上赚钱。（而这已经初见端倪，因为科技公司的强势崛起，google和阿里的ipo案例里，都是投行把客户当成大爷，这跟以往投行话语权远超上市公司是截然不同的）因为我对金融领域也不是很理解，这部分臆想的成分较多 ​ 我看国家在2016年发布135国家战略发展规划中，人工智能占了两个栏目，大数据/数据挖掘占了一个栏目，物联网占了一个栏目。我国从汉代开始就有着官山海的中央金融集权制度，既从科技发展趋势来看，又从国家支持的角度来看，人工智能不管还能不能在科研界火下去，在工业界应该会挺长时间都是热门，但准入门槛应该会逐步降低（类似软件开发的学习门槛相比移动端开始的时期也降低了挺多的） ​ 武辉老师一直都想蹭一个热点，比如区块链，其实从科研的角度来说，我个人认为不是热点才是常态，现在机器学习的研究本身就能作为工业应用，最多的paper从企业的实验室里出出来本身就是很特殊的。 ​ 从科研成果的角度我不清楚怎么样好发论文，但我觉得从吸引学生的角度来讲区块链方面不是很好找热点的话，不如更多的注重物联网方面，阿里巴巴在马来西亚和杭州都建立了智能城市，（目前还只用在了交通方面，但以后用在其他方面时肯定很需要很多的计算力，这样老师研究的云计算/雾计算都还比较有用武之地了）除此之外，国家对新零售战略很注重，阿里花90亿美金收购了饿了吗，腾讯收购了沃尔玛。我看了下阿里旗下新零售盒马生鲜的报道，里面提及了特别注重供货商的及时送货和送货路线规划，算法层面感觉会用到运筹学的理论，数据情景也和老师研究的问题挺像的。 ​ 如果有大佬看了，轻拍吧。]]></content>
  </entry>
  <entry>
    <title><![CDATA[xgboost]]></title>
    <url>%2F2018%2F03%2F16%2Fxgboost%2F</url>
    <content type="text"><![CDATA[安装过程中出现的问题按照brew install gcc@5 pip install xgboost的方式安装出错，经过查阅stackoverflow和仔细阅读报错说明，“command python setup.py egg_info failer with error 1” 可以认定pip安装时少安装了链接文件，感觉这是在做pip安装包的bug。MAC电脑多半会出现这个错误，于是将解决方案分享给大家。 123456789git clone --recursive https://github.com/dmlc/xgboost.gitcd xgboost./build.shcd python-packagepython3 setup.py install 运行以上命令即可，其实就是从github上下载源码然后来编译啦。 简单利用xgboost来提高分类性能据说这是一个非常强大的库，可以直线提高原有模型的准确度。如果对它的原理和参数具体调优设置有兴趣的可以移步到这个博文，在下才疏学浅，就讲讲自己的简单认识吧： xgboost的基本算法原型是决策树 决策树模型的基础上进行对样本重抽样，然后多个树平均 就得到了 Tree bagging算法 Tree bagging 算法基础上进行对特征的随机挑选就形成了随机森林算法 随机森林中多个决策树进行加权平均就得到了Boosing算法 Boosting算法一般会出现过拟合现象，于是加入了惩罚因子，树越深，因子越大，同时加入了并行计算的方法就形成了现有的 xgboosting算法了 1234567891011121314151617181920212223from xgboost import XGBClassifierparams=&#123;'booster':'gbtree','objective': 'multi:softmax', #多分类的问题'num_class':10, # 类别数，与 multisoftmax 并用'gamma':0.1, # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。'max_depth':12, # 构建树的深度，越大越容易过拟合'lambda':2, # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。'subsample':0.7, # 随机采样训练样本'colsample_bytree':0.7, # 生成树时进行的列采样'min_child_weight':3, # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言#，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。#这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.'eta': 0.007, # 如同学习率'seed':1000, #随机种子'nthread':7,# cpu 线程数#'eval_metric': 'auc'&#125;clf = XGBClassifier(params)Learn=CalibratedClassifierCV(clf, method='isotonic', cv=2)Learn.fit(X_train, y_train)]]></content>
  </entry>
  <entry>
    <title><![CDATA[线性回归实现]]></title>
    <url>%2F2018%2F03%2F16%2F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[一元回归基本实现与向量化线性回归本质上是处理最优化的问题，即找到a和b，使得$\sum(y{i} - ax{i} - b)^2$ 的值 尽可能小。 公式推导如下图 接着让我们来实现一元线性回归的方法吧 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import numpy as npclass LinearRegression: def __init__(self): self.a = 0 self.b = 0 def fit(self, x_train,y_train): assert x_train.ndim == y_train.ndim == 1, "This is a single variable LinearRegression model" assert len(x_train) == len(y_train), "the size of x_train must equal to the size of y_train" x_mean = np.mean(x_train) y_mean = np.mean(y_train) #基本实现 ''' numerator = 0.0 denominator = 0.0 for x, y in zip(x_train, y_train): numerator += (x*y-x*y_mean) denominator += (x*x - x*x_mean) self.a = numerator / denominator self.b = y_mean - self.a * x_mean ''' #向量化实现 self.a = (x_train - x_mean).dot(y_train - y_mean) / (x_train - x_mean).dot(x_train - x_mean) self.b = y_mean - self.a * x_mean return self def predict(self, topredict): assert topredict.ndim == 1, "This is a single variable LinearRegression model" assert self.a is not None and self.b is not None, "Must fit before" return np.array([self._predict(i) for i in topredict]) def _predict(self, x): return self.a * x + self.b def accuracy_score(self, y_true, y_predict): assert y_true.shape[0] == y_predict.shape[0], "the size of y_true must be equal to the size of y_predict" return sum(y_true == y_predict) / len(y_true) def score(self, x_test, y_test): y_predict = self.predict(x_test) return self.accuracy_score(y_test, y_predict) def __repr__(self): return "My single variable simpleLinearRegression"x = np.array([1., 2., 3., 4., 5.])y = np.array([2., 3., 4., 5., 6.])model = LinearRegression()model.fit(x,y)y_1 = model.predict(x)print(y_1)#print(model.score(y_1, y)) 事实上我在上图中推导的公式并非最简的，经过下图的推导可以进一步简化。 同时代码方面也可以优化成向量的形式，通过向量运算而非循环迭代可以极大地提高cpu计算效率，而且编译器／操作系统会自发地执行并行计算，加快计算速度。 代码上面部分中就可以见到了。 多元线性回归多元线性回归最关键的是公式的推导，根据维基百科等现有资料，将推导过程呈现如下。 代码的实现是蛮容易的，也是像上文一样调用numpy的内置函数做向量化运算的处理。 1234567891011121314151617181920import numpy as npclass LinearRegression: def __init__(self): self.coefficient = None self.intercept_ = None self._theta = None def fit_normal(self, X_train, y_train): X_b = np.hstack([np.ones((len(X_train), 1)), X_train]) self._theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train) self.intercept_ = self._theta[0] self.coefficient = self._theta[1:] return self def predict(self, X_predict): X_b = np.hstack([np.ones((len(X_predict), 1)), X_predict]) return X_b.dot(self._theta) def __repr__(self): return "My Multivariable LinearRegression"]]></content>
  </entry>
  <entry>
    <title><![CDATA[sklearn中使用KNN的范例]]></title>
    <url>%2F2018%2F03%2F14%2Fsklearn%E4%B8%AD%E4%BD%BF%E7%94%A8KNN%E7%9A%84%E8%8C%83%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[导论数据挖掘建模中一个非常常见的应用就是商品购买预测，本文将利用sklearn中的KNN算法来做这个案例，最终展现我们预测结果的二维等高线填充地图和实际结果的散点分布。 详解数据格式如下图 常规的做法是要将male和female转换为数值型变量，在本例中暂不做此操作。接着我们要将年龄和预计收入归一化。这是因为收入的数值远大于年龄的数值，考虑到KNN算法的特性，不如此的话将导致收入的影响极大，年龄影响极小。于是我们采用了均值方差归一化的方法。 1234from sklearn.preprocessing import StandardScalersc = StandardScaler()X_train = sc.fit_transform(X_train)X_test = sc.transform(X_test) 12345678#绘制我们预测结果的二维等高线填充地图X_set, y_set = X_train, y_trainX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('red', 'green')))#根据我们的预测值0，1来确定不同点\区域的颜色是红或者绿plt.xlim(X1.min(), X1.max())plt.ylim(X2.min(), X2.max()) 显示如下 最终我们将实际的结果以散点图的形式绘制出来，同样以红绿两色表示二分类问题。 代码如下 123456789for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j) plt.title('K-NN (Training set)')plt.xlabel('Age')plt.ylabel('Estimated Salary')plt.legend()plt.show() 全部代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import numpy as npimport matplotlib.pyplot as pltimport pandas as pddataset = pd.read_csv('Social_Network_Ads.csv')X = dataset.iloc[:, [2, 3]].valuesy = dataset.iloc[:, 4].valuesfrom sklearn.cross_validation import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)from sklearn.preprocessing import StandardScalersc = StandardScaler()X_train = sc.fit_transform(X_train)X_test = sc.transform(X_test)from sklearn.neighbors import KNeighborsClassifierclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)classifier.fit(X_train, y_train)y_pred = classifier.predict(X_test)from sklearn.metrics import confusion_matrixcm = confusion_matrix(y_test, y_pred)# Visualising the Training set resultsfrom matplotlib.colors import ListedColormapX_set, y_set = X_train, y_trainX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('red', 'green')))plt.xlim(X1.min(), X1.max())plt.ylim(X2.min(), X2.max())for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j) plt.title('K-NN (Training set)')plt.xlabel('Age')plt.ylabel('Estimated Salary')plt.legend()plt.show()'''from matplotlib.colors import ListedColormapX_set, y_set = X_test, y_testX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('red', 'green')))plt.xlim(X1.min(), X1.max())plt.ylim(X2.min(), X2.max())for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)plt.title('K-NN (Test set)')plt.xlabel('Age')plt.ylabel('Estimated Salary')plt.legend()plt.show()''']]></content>
  </entry>
  <entry>
    <title><![CDATA[sql语言优化（1）]]></title>
    <url>%2F2018%2F03%2F14%2Fsql%E8%AF%AD%E8%A8%80%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[基本认识sql语言不是图灵完备的，顾名思义，它是不能作出图灵机的。从中也可以见的它的语法是蛮简单的。 几个基本优化方法虽然基本语法很简单，大家看看就会了。但是每一个数据提取，修改的操作效率都具有很大提升空间。 使用join 代替in在这个博客地址中http://openxtiger.iteye.com/blog/1911228 ，作者做了实验证明了join操作会比子查询效率高很多。事实上，子查询操作要循环多次查找子表，耗时较多，而join方法会将多个表格连接起来，可以避免多次循环查找的问题。 比如下面这两个写法是等价的 1234select * from hotel_info_original as c left join hotel_info_collection h on c.hotel_type=h.hotel_type and c.hotel_id =h.hotel_id where h.hotel_id is null 12select c.* from hotel_info_original where c.hotel_id not in (select h.hotel_id from hotel_info_collection where h.hotel_type = c.hotel_type) Left join是左连接，即从左表(A)产生一套完整的记录,与匹配的记录(右表(B)) .如果没有匹配,右侧将包含null 实际上它是将左表和右表完全拼接起来，不满足on中条件的全部变成NULL。因此在数据库操作过程中，要尽量的多将语句写在on中，这样可以减少where查询时间，也能够提高效率。还不理解的，可以看下图实例再揣摩一下 使用工具进行大表修改我们知道在实际应用过程中，当对大表进行修改数据类型时，会造成数据库结构较大的变动。此时mysql会锁表，一切请求只能读不能写，造成大量请求排队，效率极低。因此一个改进的办法就是在主服务器重新建一个表，在旧表上每个entry都安装触发器，修改的请求将会在旧表上进行。这些变化再同步到新表中。 实际编程较繁琐，起码我不会QUQ 但是大佬们帮我们封装好了工具，那就是pt-online-schema-change，自己去官网上免费下载安装就好啦。 基本参数信息如下 --host=xxx --user=xxx --password=xxx连接实例信息，缩写-h xxx -u xxx -p xxx，密码可以使用参数--ask-pass 手动输入。 --alter 结构变更语句 D=db_name,t=table_name指定要ddl的数据库名和表名 --execute确定修改表，则指定该参数。真正执行alter。 --execute确定修改表，则指定该参数。真正执行alter。–dry-run与–execute必须指定一个，二者相互排斥 --execute确定修改表，则指定该参数。真正执行alter。–dry-run与–execute必须指定一个，二者相互排斥 --execute确定修改表，则指定该参数。真正执行alter。–dry-run与–execute必须指定一个，二者相互排斥 123pt-online-schema-change -ujacky -p xxx -h "10.0.201.34" D=confluence,t=sbtest3 \--alter "CHANGE pad f_pad varchar(60) NOT NULL DEFAULT '' " \--execute]]></content>
  </entry>
  <entry>
    <title><![CDATA[梯度下降法简单实现]]></title>
    <url>%2F2018%2F03%2F13%2F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[KNN算法的简单实现]]></title>
    <url>%2F2018%2F03%2F13%2FKNN%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[导论KNN算法可以形象的理解成是找出离点A最近的K个点，根据这K个点中不同属性的个数来确定A的属性是怎样的。（在实际问题中，高维空间中点的各个坐标表示了一个特征，属性表示了特征代表的结果。）它可以说是最简单的机器学习算法了，但具有这高数据敏感性和算法复杂度高的问题。 实现模仿sklearn的借口，写了简单的一个KNN的类 KNN算法最终有个投票环节，简单版本是A点周围K个点，每个点都只能投一票，更复杂的版本是根据距离来设定投票的权重，距离近则权重大，可以拥有不止一票的投票权 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102from math import sqrtimport numpy as npimport matplotlib.pyplot as pltimport matplotlibfrom sklearn import datasetsfrom collections import Counterclass KNN_classifier: def __init__(self, k): assert k &gt;= 1, "k must be valid" self.k = k self._X_train = None self._y_train = None def fit(self, X_train, y_train): assert X_train.shape[0] == y_train.shape[0], \ "the size of X_train must be equal to the size of y_train" assert self.k &lt;= X_train.shape[0], \ "the size of X_train must be at least k." self._X_train = X_train self._y_train = y_train return self def predict(self, X_predict): assert self._X_train is not None and self._y_train is not None, \ "must fit before predict!" assert X_predict.shape[1] == self._X_train.shape[1], \ "the feature number of X_predict must be equal to X_train" y_predict = [self._predict(x) for x in X_predict] return np.array(y_predict) def _predict(self, x): assert x.shape[0] == self._X_train.shape[1], \ "the feature number of x must be equal to X_train" distances = [sqrt(np.sum((x_train - x) ** 2)) for x_train in self._X_train] nearest = np.argsort(distances) topK_y = [self._y_train[i] for i in nearest[:self.k]] votes = Counter(topK_y) return votes.most_common(1)[0][0] def __repr__(self): return "KNN(k=%d)" % self.k def predict_adavnce(self, X_test): assert X_test.shape[1] == self._X_train.shape[1], "the number of features in train set and test set must be equal" assert self._X_train is not None and self._y_train is not None, \ "must fit before predict!" y_predict = [self._predict_advance(x) for x in X_test] return np.array(y_predict) def _predict_advance(self, x): assert x.shape[0] == self._X_train.shape[1], "the number of features in train set and test set must be equal" distances = [sqrt(np.sum((train - x)**2)) for train in self._X_train] #print(sum(i == 0 for i in distances)) nearest = np.argsort(distances) topK_y = [self._y_train[i] for i in nearest[:self.k]] #print(topK_y) votes = Counter() for i in nearest[:self.k]: votes[self._y_train[i]] += (1/(distances[i]**2 + 1)) # 1/i #print(votes.most_common(1)[0][0]) return votes.most_common(1)[0][0] def train_test_split(self, X,y, text_ratio, seed = 0 ): assert X.shape[0] == y.shape[0], "the size of X must be equal tp teh size of y" assert 0.0 &lt;= text_ratio &lt;= 1.0, "text_ratio must be valid" if seed: np.random.seed(seed) shuffleindex = np.random.permutation(len(X)) text_size = int(len(X) * text_ratio) train_index = shuffleindex[text_size:] test_index = shuffleindex[:text_size] x_train = X[train_index] y_train = y[train_index] x_test = X[test_index] y_test = y[test_index] return x_train, x_test,y_train,y_test def score(self, x_test, y_test): y_predict = self.predict(x_test) return accuracy_score(y_test, y_predict) def accuracy_score(test, predict): return sum(test == predict) / len(predict)digits = datasets.load_digits()X = digits.datay = digits.targettemp = KNN_classifier(3)from sklearn.cross_validation import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)my_knn_clf = KNN_classifier(k=3)my_knn_clf.fit(X_train, y_train)#y_predict = my_knn_clf.predict(X_test)print(X_test.shape)y_predict = my_knn_clf.predict_adavnce(X_test)print(y_predict.shape)print(y_test.shape)print(sum(y_test == y_predict) / len(y_test)) 以上代码中predict_advance是高级版本的实现，利用手写数字的数据集发现写的代码没错，准确率还是蛮高的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[semantic 学习]]></title>
    <url>%2F2018%2F01%2F28%2Fsemantic-%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[介绍Semantic UI是一个在github上已经获得39264个star的漂亮的css框架，它具有语义化特点，也就是说语法特别容易上手。 安装与简单使用安装教程在官网。 分为简单安装和完全安装。简单安装只要下载了对应的css和js文件即可，我们在写前端时，引用对应的文件即可。 完全安装较麻烦一些，但可以支持更换主题，定制各按钮，表格样式等操作。 注意，如果只是简单安装的话，官网上给出的include in your html需要注意更改文件目录 我们可以在官方文档中找到多个样式的代码，看哪个自己喜欢的就复制粘贴一下，如下面的代码自己就能在网页中显示图中的效果。 1234567&lt;link rel="stylesheet" type="text/css" href="/Users/yangyuanhao/semantic/dist/semantic.min.css"&gt;&lt;script src="https://code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"&gt;&lt;/script&gt;&lt;script src="semantic/dist/semantic.min.js"&gt;&lt;/script&gt;&lt;button class="ui button"&gt;Follow&lt;/button&gt; 更换主题与样式修改当我们使用Semantic UI来构建网页时，我们有时候会发现自己的网页打开的比较慢，这是由于国内的网络环境造成的。 网站的整体布局inverted 反色处理 左右边距可以用container segment左右无空，用于网页底部等 grid]]></content>
  </entry>
  <entry>
    <title><![CDATA[经济机器是如何运转的]]></title>
    <url>%2F2018%2F01%2F27%2F%E7%BB%8F%E6%B5%8E%E6%9C%BA%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%90%E8%BD%AC%E7%9A%84%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[奥斯维辛:一部尘封的历史]]></title>
    <url>%2F2018%2F01%2F27%2F%E5%A5%A5%E6%96%AF%E7%BB%B4%E8%BE%9B-%E4%B8%80%E9%83%A8%E5%B0%98%E5%B0%81%E7%9A%84%E5%8E%86%E5%8F%B2%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[jquery实现记事本]]></title>
    <url>%2F2018%2F01%2F27%2Fjquery%E5%AE%9E%E7%8E%B0%E8%AE%B0%E4%BA%8B%E6%9C%AC%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[大明1556]]></title>
    <url>%2F2018%2F01%2F27%2F%E5%A4%A7%E6%98%8E1556%2F</url>
    <content type="text"><![CDATA[当国家（政府）有难时，牺牲的一定是平民百姓或商人。 （当民情汹涌时，）为了社会稳定，政府一定会牺牲政治斗争失败的官员或商人。]]></content>
  </entry>
  <entry>
    <title><![CDATA[东野圭吾的《白金数据》]]></title>
    <url>%2F2018%2F01%2F26%2F%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE%E7%9A%84%E3%80%8A%E7%99%BD%E9%87%91%E6%95%B0%E6%8D%AE%E3%80%8B%2F</url>
    <content type="text"><![CDATA[考完试后回到家里，闲来无事便读了一个下午读完了这本新出的侦探小说。比较符合我对东野圭吾的预期，小说很有悬念，比较刺激，但文学性和思想性不足，只是消遣性读物。 后面会涉及严重剧透======================================= 故事主要描述了日本想全国范围内收集民众的DNA数据，从而通过罪犯遗留下来的任何可能携带基因的物品，达到快速找到罪犯亲属或罪犯的目的。但这样巨大的工程容易造成民众隐私的泄漏，同时在小说中通过一系列无法通过基因数据库找到罪犯消息的犯罪案件和主角的被嫁祸，几个重要配角的反转，揭示了政府重要官员在数据库中做的手脚——他们的亲属犯罪将无法通过基因匹配找到罪犯的信息，自然的也将无法通过基因匹配查到他们身上。 这些政府官员的数据就是白金数据。 小说想向我们揭示大数据技术下个人隐私泄漏的可能，这不过是老生常谈。支付宝之前的年度账单事件就拔出萝卜带着泥，牵扯了一大批不合理读取用户个人数据的app。可以想象对掌控着我们所有社交信息的腾讯公司而言，我们几乎就是白纸一张，一切都能被人一眼望到底。 作者还想引起我们的思考，人心到底是不是完全物质化的呢？毕竟激素，神经递质，他们主宰着我们的情绪和思想。随着技术的进步，我们完全可以人造情感和思想。无奈太过浅尝辄止，作者本身并没有通过故事深入讨论这个话题。 东野圭吾应该也试图展示政府高级官员的龌龊。太阳底下没有新鲜事，全国范围内收集民众的DNA数据是一个涉及法律和公安执法的变革，历朝历代的变革根本目的都是更好地维护统治阶级的利益。屁股决定脑袋，换成说是日本政坛大佬都会这样做的。君王一怒，伏尸百万，流血漂橹。相比之下，放点儿白金数据都是小儿科的了。网上不就有纪录片和帖子讨论朴槿惠为了邪教献祭牺牲了岁月号三百多名学生的事情吗？想想令人毛骨悚然，但再想想史书不绝于笔的“族”，又为之泰然。详情]]></content>
  </entry>
  <entry>
    <title><![CDATA[利用随机森林法预测Titanic乘客生存率]]></title>
    <url>%2F2018%2F01%2F26%2F%E5%88%A9%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%B3%95%E9%A2%84%E6%B5%8BTitanic%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E7%8E%87%2F</url>
    <content type="text"><![CDATA[问题描述在kaggle上有一个竞赛题目，是如何根据泰坦尼克号上的已知的乘客数据来预测某一乘客在该轮船上能否存活。题目本身就是一道供初学者进行数据分析学习的问题，也有很多大佬给出了自己的数据训练的tutorial，自己就在这里分享下自己在借鉴了一些大佬的经验之后给出的自己的解决方案。 解决流程数据清洗数据清洗是所有数据分析问题第一步要解决的，我们首先来看下官方对数据集的说明。 PassengerId: 编号 Survived: 0 = 死亡，1 = 生存 Pclass: 船票级别 1 = 高级， 2 = 中等， 3 = 低等 Name: 名称 Sex: male = 男性，female = 女性 Age: 年龄 SibSp: 在 Titanic 上的兄弟姐妹以及配偶的人数 Parch: 在 Titanic 上的父母以及子女的人数 Ticket: 船票编号 Fare: 工资 Cabin: 所在的船舱 Embarked: 登船的港口 C = Cherbourg, Q = Queenstown, S = Southampton 接下来我们让我们读取数据并对数据有一个初步的感性认识。 我们首先来做定性分析，看一下特征类别分布是否平衡。类别平衡指分类样例不同类别的训练样例数目差别不大。当差别很大时，为类别不平衡。当类别不平衡的时候，例如正反比为 9:1，学习器将所有样本判别为正例的正确率都能达到 0.9。这时候，我们就需要使用 “再缩放”、“欠采样”、“过采样”、“阈值移动” 等方法。如下图，我们发现总体而言还是特征分布还是平衡的，活下来的人和死亡人数没有偏差过多。 删除无必要数据空数据处理我们来看看有多少空数据 对空数据我们怎么处理呢，这就要分情况讨论啦。 Age作图 Age ~ Survived。年龄较小的孩子生存的几率大。 因为年龄是一个连续值，而且他会对预测结果产生影响，同时我们发现不同群体中年龄的分布是不同的。 因此我们根据票的等级，在 Titanic 上的兄弟姐妹以及配偶的人数，在 Titanic 上的父母以及子女的人数来将数据分为不同的集合，再用缺失数据所在集合的平均值来进行填充。并判断最后的对 Age ~ Survived 的性质并未产生影响。 Embarked它缺少的数据只有两个，直接用众数填充即可。 Cabin他的数据较为复杂，Cabin 特征值由字母开头，判断船舱按字母分为A，B，C… 于是我们仅提取字母编号，降低维度。然后使用新的字母‘U’填充缺失数据。我们发现缺失数据的游客主要是三等舱的，并且这部分游客的生存率相对较低。 数值化和标准化数值化Ticket 特征值中的一串数字编号对我们没有意义，忽略。下面代码中，我们用正则表达式过滤掉这串数字，并使用 pandas get_dummies 函数进行数值化（以 Ticket 特征值 作为新的特征，0,1 作为新的特征值）。 123456789101112Ticket=[]import rer=re.compile(r'\w*')#正则表达式，查找所有单词字符[a-z/A-Z/0-9]for i in data['Ticket']: sp=i.split(' ')#拆分空格前后字符串，返回列表 if len(sp)==1: Ticket.append('U')#对于只有一串数字的 Ticket，Ticket 增加字符 'U' else: t=r.findall(sp[0])#查找所有单词字符，忽略符号，返回列表 Ticket.append(''.join(t))#将 t 中所有字符串合并data['Ticket']=Ticketdata=pd.get_dummies(data,columns=['Ticket'],prefix='T')#get_dummies：如果DataFrame的某一列中含有k个不同的值，则可以派生出一个k列矩阵或DataFrame（其值全为1和0） getdummies是处理类别醒数据很好的一种方式，这样我们可以将离散的分类变成具体的0，1特征向量，很大程度的加速了电脑计算的速度和监督学习最后训练得到的准确率。对cabin和embarked同样做此操作。最后得到的特征向量如图 标准化偏态分布偏态分布的数据有时不利于模型发现数据中的规律，我们可以使用 Log Transformation 来处理数据，这样可以提高训练的准确度。比如Fare这一特征就存在明显的偏态分布，我们skitlearn提供的函数进行处理，参考 Skewed Distribution and Log Transformation 离群点删除离群点是显著偏离数据集中其余对象的点。离群点来源于操作失误，数据本身的可变性等。我们这里采用箱线法,检测特征 [‘Age’, ‘Parch’, ‘SibSp’, ‘Fare’]的离群点。参考离群点和箱线法 123456789101112131415161718192021222324from collections import Counterdef outlier_detect(n, df, features):#定义函数 outlier_detect 探测离群点，输入变量 n, df, features，返回 outlier outlier_index = [] for feature in features: Q1 = np.percentile(df[feature], 25)#计算上四分位数（1/4） Q3 = np.percentile(df[feature], 75)#计算下四分位数（3/4） IQR = Q3 - Q1 outlier_span = 1.5 * IQR col = ((data[data[feature] &gt; Q3 + outlier_span]) | (data[data[feature] &lt; Q1 - outlier_span])).index outlier_index.extend(col) print('%s: %f (Q3+1.5*IQR) , %f (Q1-1.5*QIR) )' % (feature, Q3 + outlier_span, Q1 - outlier_span)) outlier_index = Counter(outlier_index)#计数 outlier = list(i for i, j in outlier_index.items() if j &gt;= n) print('number of outliers: %d' % len(outlier)) print(df[['Age', 'Parch', 'SibSp', 'Fare']].loc[outlier]) return outlieroutlier = outlier_detect(3, data, ['Age', 'Parch', 'SibSp', 'Fare'])#调用函数 outlier_detectdata = data.drop(outlier) 模型选择与训练模型介绍Boosting模型与bagging模型Bagging：假设我有一个大小为n的训练集D，bagging会从D中有放回的均匀地抽样，假设我用bagging生成了m个新的训练集Di，每个Di的大小为j。由于我有放回的进行抽样，那么在Di中的样本有可能是重复的。如果j=n，这种取样称为bootstrap取样。现在，我们可以用上面的m个训练集来拟合m个模型，然后结合这些模型进行预测。对于回归问题来说，我们平均这些模型的输出;对于分类问题来说，我们进行投票（voting）。 Boosting：Boosting与Bagging主要的不同是：Boosting的base分类器是按顺序训练的（in sequence），训练每个base分类器时所使用的训练集是加权重的，而训练集中的每个样本的权重系数取决于前一个base分类器的性能。如果前一个base分类器错误分类地样本点，那么这个样本点在下一个base分类器训练时会有一个更大的权重。一旦训练完所有的base分类器，我们组合所有的分类器给出最终的预测结果。过程如下图： Adaboost与RandomForest算法Adaboost是一种基于boosting模型的迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。 Adaboost的结构:最后的分类器YM是由数个弱分类器（weak classifier）组合而成的,相当于最后m个弱分类器来投票决定分类结果，而且每个弱分类器的“话语权”因子α大小不一样。 Randomforest是基于bangging模型实现的，他的元分类器是决策树。过程简要概括如下： 从原始训练集中进行bootstrap抽样 用步骤1中的bootstrap样本生成决策树 随机选择特征子集 用上面的特征子集来拆分树的节点 重复1和2两个步骤 集成所有生成的决策树进行预测 模型评估我们采用k 折交叉验证法，更具体的是10 折交叉验证法。 k 折交叉验证（k-fold cross validation）：将 D 划分 k 个大小相似的子集（每份子集尽可能保持数据分布的一致性：子集中不同类别的样本数量比例与 D 基本一致），其中一份作为测试集，剩下 k-1 份为训练集 T，操作 k 次。 例如 D 划分为 D1，D2，… ，D10，第一次使用 D1 作为训练集，第二次使用 D2，第三次使用 D3， … ， 第十次使用 D10 作为测试集。最后计算 k 次测试误差的平均值近似泛化误差。 12345678y = data['Survived']X = data.drop(['Survived'], axis=1).valuesclassifiers = [AdaBoostClassifier( random_state=2), RandomForestClassifier(random_state=2)]for clf in classifiers: score = cross_val_score(clf, X, y, cv=10, scoring='accuracy')#cv=10：10 折交叉验证法，scoring='accuracy'：返回测试精度 print([np.mean(score)])#显示测试精度平均值 我们可以发现随机森林分类器的准确率要高不少。 模型训练但是随机森林是基于决策树的，决策树一直存在着过拟合的问题。 过拟合是学习器性能过好，把样本的一些特性当做了数据的一般性质，从而导致训练误差低但泛化误差高。学习曲线是判断过拟合的一种方式，同时可以判断学习器的表现。学习曲线包括训练误差（或精度）随样例数目的变化曲线与测试误差（或精度）随样例数目的变化曲线。 接下来通过绘制学习曲线，我们发现训练误差始终接近 0，而测试误差始终偏高，说明存在过拟合的问题。 123456789101112131415161718192021222324252627282930313233from sklearn.model_selection import learning_curveimport matplotlib.pyplot as pltdef plot_learning_curve(estimator, title, X, y, cv=10, train_sizes=np.linspace(.1, 1.0, 5)):#定义函数 plot_learning_curve 绘制学习曲线。train_sizes 初始化为 array([ 0.1 , 0.325, 0.55 , 0.775, 1. ]),cv 初始化为 10，以后调用函数时不再输入这两个变量 plt.figure() plt.title(title)#设置图的 title plt.xlabel('Training examples')#横坐标 plt.ylabel('Score')#纵坐标 train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, train_sizes=train_sizes)#使用 10 折交叉验证法，对 train_sizes*m（m为总的样例数目） 个的数据进行训练，返回训练精度 train_scores,测试精度 test_scores train_scores_mean = np.mean(train_scores, axis=1)#计算平均值 train_scores_std = np.std(train_scores, axis=1)#计算标准差 test_scores_mean = np.mean(test_scores, axis=1) test_scores_std = np.std(test_scores, axis=1) plt.grid()#设置背景的网格 plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='g')#设置颜色 plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='r') plt.plot(train_sizes, train_scores_mean, 'o-', color='g', label='traning score')#绘制训练精度曲线 plt.plot(train_sizes, test_scores_mean, 'o-', color='r', label='testing score')#绘制测试精度曲线 plt.legend(loc='best') return pltg = plot_learning_curve(RandomForestClassifier(), 'RFC', X, y)#调用函数 plot_learning_curve 绘制随机森林学习器学习曲线 要解决这一问题只能通过调参。 skitlearn中的randomforestclassifer函数具有非常多的参数，列举几个如下。 参数 特点 n_estimators 基学习器数目（默认值10） 基本趋势是值越大精度越高 ，直到达到一个上限 criterion 选择算法 gini 或者 entropy (默认 gini) 视具体情况定 max_features 2.2.3节中子集的大小，即k值（默认 sqrt(n_features)） max_depth 决策树深度 过小基学习器欠拟合，过大基学习器过拟合。粗调节 max_leaf_nodes 最大叶节点数（默认无限制） 粗调节 min_samples_split 分裂时最小样本数，默认2 细调节,越小模型越复杂 min_samples_leaf 叶节点最小样本数，默认2 细调节，越小模型越复杂 bootstrap 是否采用自助法进行样本抽样（默认使用） 决定基学习器样本是否一致 我们先通过尝试找到最好的n_estimators和max_depth，max_leaf_nodes 参数 1234567891011121314151617181920def para_tune(para, X, y): # clf = RandomForestClassifier(n_estimators=para) #n_estimators 设置为 para score = np.mean(cross_val_score(clf, X, y, scoring='accuracy')) return scoredef accurate_curve(para_range, X, y, title): score = [] for para in para_range: score.append(para_tune(para, X, y)) plt.figure() plt.title(title) plt.xlabel('Paramters') plt.ylabel('Score') plt.grid() plt.plot(para_range, score, 'o-') return pltg = accurate_curve([2, 10, 50, 100, 150], X, y, 'n_estimator tuning') 与上面代码类似的我们可以得到下面三张图 接着我们就可以固定这三个影响较大的参数，再利用自动调参函数GridSearchCV来对其他的参数进行粗略的调节。 如此我们得到了最终0.8204的准确率。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python作图]]></title>
    <url>%2F2018%2F01%2F25%2Fpython%E4%BD%9C%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[导论作图工具如恒河沙数，最好用的就是excel的图表功能，还有powermap这样强大的插件，可以非常轻松的解决工作制作报表的问题。但是excel的图表自定义功能并不够强大，在工程和数据科学领域，excle也捉襟见肘。相比之下matlab，mathmeticas这样的商业软件就非常优秀了，然而我偏不它们。我接下来要讲的是python中的Matplotlib和seaborn这样的函数库。 Matplotlib在 Matplotlib 中，大部分图形样式的绘制方法都存在于 pyplot 模块中，一共有160多种图表绘制方法。 2D图绘制我们首先用接下来的代码来引用科学计算函数库numpy和图形绘制库matplotlib 用npm可以很简单地安装好啦，我就不多说了。 12import numpy as npimport matplotlib as plt 然后我们来用下面的代码生成数据 12X = np.linspace(-2*np.pi,2*np.pi,1000) #在-2*np.pi和2*np.pi之间等间隔的生成1000个数据点，X就是一个np 数组Y = np.sin(X)#Y也是一个数组，对应了X的sin值 接着我们键入一下代码，分别生成线型图，柱形图和散点图 123plt.pyplot.plot(X,Y)plt.pyplot.bar(X,Y)plt.pyplot.scatter(X,Y) 输出如下 再接着我们可以尝试着画饼状图，量场图和等高线图 1234z = [1,2,3]plt.pyplot.pie(z)#饼被分成三块，每块的相对面积大小是1，2，3X, y = np.mgrid[0:10, 0:10]#表示的是一个矩阵plt.pyplot.quiver(X, y) 图形输出如下 这样子的功能其实excel也可以实现，还比python要简单，下面是体现python强大的图形自定义功能的时刻到啦 线型图线型图通过 matplotlib.pyplot.plot(args, *kwargs) 方法绘出。其中，args 代表数据输入，而 kwargs 的部分就是用于设置样式参数了。 123456789X = np.linspace(-2 * np.pi, 2 * np.pi, 1000)# 计算 sin() 对应的纵坐标y1 = np.sin(X)# 计算 cos() 对应的纵坐标y2 = np.cos(X)# 向方法中 `*args` 输入 X，y 坐标plt.pyplot.plot(X, y1, color='r', linestyle='--', linewidth=2, alpha=0.8)plt.pyplot.plot(X, y2, color='b', linestyle='-', linewidth=2) 我们就能见到这样漂亮的图拉 样式参数有很多，具体的可以见下表，更具体的麻烦查阅下官方文档]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hexo + Github Pages博客创建历程]]></title>
    <url>%2F2018%2F01%2F24%2F%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2%E5%88%9B%E5%BB%BA%E5%8E%86%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言对程序员来说，纸上得来终觉浅，绝知此事要躬行，每分专业的能力绝不是看书看来的，听课听来的，而一定要是自己一行一行代码敲来的。不仅如此，每个不甘寂寞的程序猿（媛），还会有着创建一个博客，发布自己所见所感所学的想法或习惯。为了更好地促进自己的进步，我也来加入写博客的大军啦。 怎样的博客应该以什么样的方式来创建博客是本节的重点。 在大一时，为了应付一门课的作业自己开通了cdsn的博客，有很多大牛的博客就扎根在了cdsn。但是对我而言，cdsn总有着烦人的广告，下载资料的时候还总要花钱充值，让我觉得很不爽，所以pass了这个选择。 还有很多人会选择简书，可那里是文艺青年的聚集地，程序员特有的geek氛围要远远差于cdsn。 至于知乎专栏和微信公众号，虽然也可以当作自己写随笔发布的园地，但与博客相比，总觉得差了点什么。 除此之外，还有wordpress和wix等建站方式，其实很方便的，可见即可得的操作，免费版的也不用花钱。主要原因还是自己嫌弃它们一点也不geek，就没有使用这种方式啦。说真的wix创建出来的网站可好看啦，而且官方的引导特别详尽，就像游戏里的引导操作一样，自己很容易就能建成一个很漂亮的网站，我当时 于是就开始考虑起自己搭建一个博客网站。自己之前尝试过用python的django框架搭建过博客网站，它自带有功能很强大的后台，当初自己实现的最终版也差强人意。一个完全由自己掌控的网站是能让人很有成就感的。可想了想自己还是没有选择这个自己实现的网站来作为自己的博客，因为除了后台功能外，自己所有都要手打代码，评论，搜索乃至前台的页面，出了bug要自己调试，万一调试不出来，博客就挂掉了。。。。 那么就考虑到了使用hexo框架来搭建博客，它并不是真正意义上代码的框架，使用它基本不需要编写代码，简介，美观，好用而功能强大。而且它与github pages可以无间合作，还可以省去了购买云主机，云服务器的花销。 创建博客的准备我们首先需要在电脑上安装好node.js , git和一些下载包管理工具如npm，homebrew（ mac自带），apt-get（Ubuntu自带），yum（centos自带）。 接着进入hexo官网，按照上面的步骤安装hexo。（此处非常有必要阅读一下hexo官方对自己的介绍） 我们此时已经安装好了hexo，可以输入以下命令检查是否安装成功，windows用户可能需要再配置一下环境变量， 接着我们输入 hexo init yournamecd yournamenpm install 这样就可以创建自己的博客文件夹，里面有网站的各个静态文件，自己以后的文章也会放在这个文件夹里，进入这个文件夹后，用npm命令来安装各项依赖。 此时我们用hexo new “文章标题”就可以新建一个文章，我们进入source文件夹内的_posts文件夹，就会发现多出了一篇md后缀的文件，这就是我们刚刚创建的文章啦，我们也可以直接在里面创建markdowm文件。接着我们用hexo s命令就能在本地运行这个简单的博客网站了。 然后在github新建一个代码仓库，仓库的名字一定要是”yourusername.github.io”。如我github账户名是yyhyplxyz，我这个代码仓库名字就是“yyhyplxyz.github.io”。 接着去github上添加ssh key，可以参考此网址ssh。]]></content>
      <tags>
        <tag>coding</tag>
      </tags>
  </entry>
</search>
